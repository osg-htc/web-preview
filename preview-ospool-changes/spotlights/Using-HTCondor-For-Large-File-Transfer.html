<!doctype html>
<html lang="en-US">
  <head  data-proofer-ignore>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<link rel="icon" href="/favicon.ico">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How to Transfer 460 Terabytes? A File Transfer Case Study | OSG</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="How to Transfer 460 Terabytes? A File Transfer Case Study" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How Greg Daues at the National Center for Super Computing Applications used HTCondor to transfer 460 terabytes of data." />
<meta property="og:description" content="How Greg Daues at the National Center for Super Computing Applications used HTCondor to transfer 460 terabytes of data." />
<meta property="og:site_name" content="OSG" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-15T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How to Transfer 460 Terabytes? A File Transfer Case Study" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-01-15T00:00:00+00:00","datePublished":"2021-01-15T00:00:00+00:00","description":"How Greg Daues at the National Center for Super Computing Applications used HTCondor to transfer 460 terabytes of data.","headline":"How to Transfer 460 Terabytes? A File Transfer Case Study","mainEntityOfPage":{"@type":"WebPage","@id":"https://osg-htc.org/spotlights/Using-HTCondor-For-Large-File-Transfer.html"},"url":"https://osg-htc.org/spotlights/Using-HTCondor-For-Large-File-Transfer.html"}</script>
<!-- End Jekyll SEO tag -->




<!-- Bootstrap 5 -->
<link rel="stylesheet" href="/web-preview/preview-ospool-changes/assets/css/style.css?v=">
<!--[if lt IE 9]>
<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<script src="/web-preview/preview-ospool-changes/assets/js/bootstrap.bundle.min.js" ></script>






  </head>
  <body>
    <header>
    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
        <div class="container-xxl">
            <a class="navbar-brand pt-1 pb-1" href="/web-preview/preview-ospool-changes/"><img height="55" src="/web-preview/preview-ospool-changes/assets/images/logos/OSG-logo.svg" alt="OSG logo"></a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarCollapse">
                <ul class="navbar-nav mr-auto">
                    <li class="nav-item dropdown active">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                            About
                        </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                            
                            
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/about/introduction/">Introduction</a>
                            
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/about/open_science_pool/">Open Science Pool</a>
                            
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/about/osdf/">Open Science Data Federation</a>
                            
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/about/organization/">Consortium Members</a>
                            
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/about/team/">The OSG Team</a>
                            
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/about/publications/">Publications</a>
                            
                            
                            <a class="dropdown-item" href="/web-preview/preview-ospool-changes/acknowledging.html">Acknowledging OSG</a>
                        </div>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="/web-preview/preview-ospool-changes/campus-cyberinfrastructure.html">Campuses</a>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="/web-preview/preview-ospool-changes/spotlight.html">Spotlight</a>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="/web-preview/preview-ospool-changes/news.html">News</a>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="/web-preview/preview-ospool-changes/events.html">Events</a>
                    </li>
                    <li class="nav-item active">
                        <a class="nav-link" href="/web-preview/preview-ospool-changes/contact.html">Contact</a>
                    </li>
                    <li class="nav-item dropdown active">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown2" role="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                            Docs
                        </a>
                        <div class="dropdown-menu" aria-labelledby="navbarDropdown2">
                            <a class="dropdown-item" href="https://support.opensciencegrid.org/support/home">For Users</a>
                            <a class="dropdown-item" href="https://opensciencegrid.org/docs/">For Sysadmins</a>
                            <a class="dropdown-item" href="https://opensciencegrid.org/security/">Security</a>
                        </div>
                    </li>
                </ul>
            </div>
        </div> <!-- End Container -->
    </nav>
</header>
    <main>
      <div class="container-xxl pt-5">
    <div class="row justify-content-center">
  <div class="col-12 col-xl-7 col-lg-8 col-md-10">
    <section class="news-article">
      
      <div class="mb-1">
        <h1>How to Transfer 460 Terabytes? A File Transfer Case Study</h1>
        
      </div> <!-- title-head -->
      

      <div class="fs-5">
        <p>When Greg Daues at the <a href="https://resources.istcoalition.org/national-center-for-supercomputing-applications" target="_blank">National Center for Supercomputing Applications (NCSA)</a> needed to transfer 460 Terabytes of NCSA files from <a href="https://in2p3.cnrs.fr/en/node/11" target="_blank">the National Institute of Nuclear and Particle Physics (IN2P3)</a> in Lyon, France to Urbana, Illinois, for a project they were working with <a href="https://www.fnal.gov/" target="_blank">FNAL</a>, <a href="https://cc.in2p3.fr/en/" target="_blank">CC-IN2P3</a> and the <a href="https://www.lsst.org/" target="_blank">Rubin Data Production team</a>, he turned to the <a href="https://research.cs.wisc.edu/htcondor/" target="_blank">HTCondor High Throughput system</a>, not to run computationally intensive jobs, as many do, but to manage the hundreds of thousands of I/O bound transfers.</p>

<h2>The Data</h2>

<p>IN2P3 made the data available via https, but the number of files and their total size made the management of the transfer an engineering challenge.  There were two kinds of files to be transferred, with 3.5 million files with a median size of roughly 100 Mb, and another 3.5 million smaller files, with a median size of about 10 megabytes.  Total transfer size is roughly 460 Terabytes.</p>

<h2>The Requirements</h2>

<p>The requirement for this transfer was to reliably transfer all the files in a reasonably performant way, minimizing the human time to set up, run, and manage the transfer.  Note the noni-goal of optimizing for the fastest possible transfer time – reliability and minimizing the human effort take priority here.  Reliability, in this context implies:</p>

<p>Failed transfers are identified and re-run (with millions of files, a failed transfer is almost inevitable)
Every file will get transferred
The operation will not overload the sender, the receiver, or any network in between</p>

<h2>The Inspiration</h2>

<p>Daues presented unrelated work at the <a href="https://research.cs.wisc.edu/htcondor/HTCondorWeek2017/" target="_blank">2017 HTCondor Week workshop</a>.  At this workshop, he heard about the work of Phillip Papodopolous at UCSD, and his international Data Placement Lab (iDPL).   iDPL used HTCondor jobs solely for transferring data between international sites.  Daues re-used and adapted some of these ideas for NCSA’s needs.</p>

<h2>The Solution</h2>
<p>First, Daues installed a <a href="https://hub.docker.com/r/htcondor/mini" target="_blank">“mini-condor”</a>, an HTCondor pool entirely on one machine, with an access point and eight execution slots on that same machine.  Then, given a single large file containing the names of all the files to transfer, he ran the Unix split command to create separate files with either 50 of the larger files, or 200 of the smaller files.  Finally, using the HTCondor submit file command</p>

<p>Queue filename matching files *.txt</p>

<p>the condor_submit command creates one job per split file, which runs the wget2 command and passes the list of filenames to wget2.  The HTCondor access point can handle tens of thousands of idle jobs, and will schedule these jobs on the eight execution slots.  While more slots would yield more overlapped i/o, eight slots were chosen to throttle the total network bandwidth used.  Over the course of days, this machine with eight slots maintained roughly 600 MB/seconds.</p>

<p><em>(Note that the machine running HTCondor did not crash during this run, but if it had, all the jobs, after submission, were stored reliably on the local disk, and at such time as the crashed machine restarted, and the init program restarted the HTCondor system, all interrupted jobs would be restarted, and the process would continue without human intervention.)</em></p>

      </div>
    </section>
  </div>
</div>



</div>
    </main>
    <footer>
    <div class="container-xxl my-5">
        <hr/>
        Funded by the National Science Foundation under Grant Nos. 2030508, 1836650, and 1148698. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.
    </div>
</footer>
  </body>
</html>
